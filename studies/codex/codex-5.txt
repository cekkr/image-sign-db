Implemented dataset evaluation mode with scoring and cropping support.

src/train.js:72 CLI parsing now handles --evaluate, --evaluate-runs, --evaluate-top, and --evaluate-filters, wiring defaults for evaluation runs.
src/train.js:626 Added evaluation helpers: filter resolution, a seeded cropping transform, per-run scoring via scoreCandidateFeature, and a final summary emitted from evaluateDataset.
src/train.js:868 New evaluation loop walks the dataset, applies the selected filters multiple times per image, reports top matches with affinity/spread, and captures aggregate accuracy stats.
src/lib/vectorGenerators.js:134 generateSpecificVector accepts an optional imageTransform, allowing evaluation filters such as cropping to preprocess each probe before augmentation.
Usage: node src/train.js <dataset_dir> --evaluate --evaluate-filters=original,cropping --evaluate-runs=3 --evaluate-top=5 prints per-image match tables plus a summary; adjust filters/runs/top as needed.

Tests not run (no automated suite provided). Suggested next steps:

Run the above --evaluate command against a trained dataset to validate outputs.
Review affinity summaries to decide if additional filters or tuning are needed.

# Affinity elasticity

Improved the similarity scoring, added elastic candidate selection, and wired training-time self-evaluation so the pipeline immediately surfaces how well each image can be rediscovered.

Reworked descriptor scoring to use affinity/cohesion with dynamic coverage so perfect matches no longer get filtered out and thresholds are configurable (src/lib/correlationMetrics.js:3, src/settings.js:55).
Introduced an elastic matcher and applied it across ingestion, evaluation, and the HTTP search path to relax thresholds on demand, capture distance stats, and log when the system has to stretch (src/lib/elasticMatcher.js:20, src/train.js:540, src/index.js:179, src/train.js:1101).
Added a queued self-evaluator that replays the evaluation probes for the first few ingests, reporting best match, self rank, and relaxed thresholds alongside training output (src/train.js:887, src/train.js:1201, src/train.js:1339).
Clarified “pattern vs. constellation” both in docs and via table comments so the schema now distinguishes positive patterns, constellations, and skip lists (README.md:45, README.md:176, src/setupDatabase.js:35).
Tests: node --check src/train.js; node --check src/index.js; node --check src/lib/elasticMatcher.js

Next steps:

Run a short node src/train.js <dataset> ingest and watch the new self-evaluation logs to confirm the original image ranks near the top.
Follow up with --evaluate to verify the reported affinity/cohesion stats align with your expectations on a larger sample.
8 files changed
+440
-86


README.md
+10
-0

index.js
+26
-20

insert.js
+1
-1

correlationMetrics.js
+18
-10

elasticMatcher.js
+121
-0

settings.js
+22
-2

setupDatabase.js
+3
-3

train.js
+239
-50

# Fixed error "Out of range value for column 'value_type_id' at row 1"

Updates

Added a schema guard that inspects value_types, feature_vectors, and feature_group_stats and upgrades their value_type columns to MEDIUMINT UNSIGNED before ingestion begins, eliminating the recurring overflow (src/lib/schema.js:1).
Wired that guard into the training entry point so the schema is checked once per session and any upgrades are reported up front (src/train.js:27, src/train.js:880).
Ensured the insert.js add CLI path applies the same guard, keeping manual ingests consistent with the training workflow (src/insert.js:13, src/insert.js:123).
Notes

I couldn’t run a live verification without access to your MySQL instance; please rerun node src/train.js … (or the insert.js add command you use) so the guard can upgrade the columns and confirm the ingestion errors disappear.